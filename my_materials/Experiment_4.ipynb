{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8cf172",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import xgboost\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "import joblib\n",
    "from joblib import dump, load\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "import gc\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307d6f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_flag = True #Если нужно тренировать модели, то флаг на 'True', если загрузить тренированные, то 'False'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4f8d2e",
   "metadata": {},
   "source": [
    "# 1. Загрузка датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa793622",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"D:\\for ML\\HW-hack\\train_hw.csv\", sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e592a92",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a38d7d2",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2531ba7e",
   "metadata": {},
   "source": [
    "# 2. Обработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0e5717",
   "metadata": {},
   "source": [
    "### 2.1 Выбор признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd750db",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_org = data[['WELL', 'DEPTH_MD', 'CALI', 'RSHA', 'RMED', 'RDEP', 'RHOB', 'GR', 'NPHI', 'PEF', 'DTC', 'SP', 'BS', 'FORCE_2020_LITHOFACIES_LITHOLOGY','FORCE_2020_LITHOFACIES_CONFIDENCE']]\n",
    "data_all = data\n",
    "data_log = data.drop(['DEPTH_MD','X_LOC','Y_LOC','Z_LOC','GROUP','FORMATION','MUDWEIGHT'], axis=1)\n",
    "data_slf = data[['WELL', 'FORMATION', 'DEPTH_MD', 'DRHO','DTC', 'SP', 'GR', 'RDEP', 'FORCE_2020_LITHOFACIES_LITHOLOGY','FORCE_2020_LITHOFACIES_CONFIDENCE']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47095e7c",
   "metadata": {},
   "source": [
    "### 2.2 Восстановление (импутация) значений"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40e9e2f",
   "metadata": {},
   "source": [
    "####  2.2.1 Разбиение на группы по скважинам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65a62f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = data_org.groupby(\"WELL\")\n",
    "well_org_fill_md = [gb.get_group(x) for x in gb.groups]\n",
    "\n",
    "gb = data_all.groupby(\"WELL\")\n",
    "well_all_fill_md = [gb.get_group(x) for x in gb.groups]\n",
    "\n",
    "gb = data_log.groupby(\"WELL\")\n",
    "well_log_fill_md = [gb.get_group(x) for x in gb.groups]\n",
    "\n",
    "gb = data_slf.groupby(\"WELL\")\n",
    "well_slf_fill_md = [gb.get_group(x) for x in gb.groups]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c44144d",
   "metadata": {},
   "source": [
    "#### 2.2.2 Импутация значений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b4e155",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Org\n",
    "d = data_org.groupby(\"FORCE_2020_LITHOFACIES_LITHOLOGY\").mean()\n",
    "for i in d.columns:\n",
    "    d[i] = d[i].fillna(d[i].mean())\n",
    "\n",
    "for i in range(len(well_org_fill_md)):\n",
    "    for j in set(well_org_fill_md[i].columns)-set(['FORCE_2020_LITHOFACIES_CONFIDENCE','FORCE_2020_LITHOFACIES_LITHOLOGY', 'WELL', 'GROUP', 'FORMATION']):\n",
    "        if well_org_fill_md[i][j].isna().sum() != len(well_org_fill_md[i][j]):\n",
    "            well_org_fill_md[i].loc[well_org_fill_md[i][j].isna(), j] = well_org_fill_md[i][j].mode().iloc[0]\n",
    "        else:\n",
    "            for t in [30000, 65000, 65030, 70000, 70032, 74000, 80000, 86000, 88000, 90000, 93000, 99000]:\n",
    "                well_org_fill_md[i].loc[well_org_fill_md[i]['FORCE_2020_LITHOFACIES_LITHOLOGY'] == t, j]  = d.loc[t, j]\n",
    "\n",
    "#All\n",
    "d = data_all.groupby(\"FORCE_2020_LITHOFACIES_LITHOLOGY\").mean()\n",
    "for i in d.columns:\n",
    "    d[i] = d[i].fillna(d[i].mean())\n",
    "\n",
    "for i in range(len(well_all_fill_md)):\n",
    "    values = {'GROUP': well_all_fill_md[i]['GROUP'].mode().iloc[0], 'FORMATION': well_all_fill_md[i]['FORMATION'].mode().iloc[0]}\n",
    "    well_all_fill_md[i] = well_all_fill_md[i].fillna(value=values)\n",
    "    for j in set(well_all_fill_md[i].columns)-set(['FORCE_2020_LITHOFACIES_CONFIDENCE','FORCE_2020_LITHOFACIES_LITHOLOGY', 'WELL', 'GROUP', 'FORMATION']):\n",
    "        if well_all_fill_md[i][j].isna().sum() != len(well_all_fill_md[i][j]):\n",
    "            well_all_fill_md[i].loc[well_all_fill_md[i][j].isna(), j] = well_all_fill_md[i][j].mode().iloc[0]\n",
    "        else:\n",
    "            for t in [30000, 65000, 65030, 70000, 70032, 74000, 80000, 86000, 88000, 90000, 93000, 99000]:\n",
    "                well_all_fill_md[i].loc[well_all_fill_md[i]['FORCE_2020_LITHOFACIES_LITHOLOGY'] == t, j]  = d.loc[t, j]\n",
    "\n",
    "#Log\n",
    "d = data_log.groupby(\"FORCE_2020_LITHOFACIES_LITHOLOGY\").mean()\n",
    "for i in d.columns:\n",
    "    d[i] = d[i].fillna(d[i].mean())\n",
    "\n",
    "for i in range(len(well_log_fill_md)):\n",
    "    for j in set(well_log_fill_md[i].columns)-set(['FORCE_2020_LITHOFACIES_CONFIDENCE','FORCE_2020_LITHOFACIES_LITHOLOGY', 'WELL', 'GROUP', 'FORMATION']):\n",
    "        if well_log_fill_md[i][j].isna().sum() != len(well_log_fill_md[i][j]):\n",
    "            well_log_fill_md[i].loc[well_log_fill_md[i][j].isna(), j] = well_log_fill_md[i][j].mode().iloc[0]\n",
    "        else:\n",
    "            for t in [30000, 65000, 65030, 70000, 70032, 74000, 80000, 86000, 88000, 90000, 93000, 99000]:\n",
    "                well_log_fill_md[i].loc[well_log_fill_md[i]['FORCE_2020_LITHOFACIES_LITHOLOGY'] == t, j]  = d.loc[t, j]\n",
    "\n",
    "#Slf\n",
    "d = data_slf.groupby(\"FORCE_2020_LITHOFACIES_LITHOLOGY\").mean()\n",
    "for i in d.columns:\n",
    "    d[i] = d[i].fillna(d[i].mean())\n",
    "\n",
    "for i in range(len(well_slf_fill_md)):\n",
    "    values = {'FORMATION': well_slf_fill_md[i]['FORMATION'].mode().iloc[0]}\n",
    "    well_slf_fill_md[i] = well_slf_fill_md[i].fillna(value=values)\n",
    "    for j in set(well_slf_fill_md[i].columns)-set(['FORCE_2020_LITHOFACIES_CONFIDENCE','FORCE_2020_LITHOFACIES_LITHOLOGY', 'WELL', 'GROUP', 'FORMATION']):\n",
    "        if well_slf_fill_md[i][j].isna().sum() != len(well_slf_fill_md[i][j]):\n",
    "            well_slf_fill_md[i].loc[well_slf_fill_md[i][j].isna(), j] = well_slf_fill_md[i][j].mode().iloc[0]\n",
    "        else:\n",
    "            for t in [30000, 65000, 65030, 70000, 70032, 74000, 80000, 86000, 88000, 90000, 93000, 99000]:\n",
    "                well_slf_fill_md[i].loc[well_slf_fill_md[i]['FORCE_2020_LITHOFACIES_LITHOLOGY'] == t, j]  = d.loc[t, j]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec04ed5",
   "metadata": {},
   "source": [
    "### 2.3 Подготовка данных к обучению"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2736bd",
   "metadata": {},
   "source": [
    "#### 2.3.1 Скалирование данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3116c87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Глубина не скалируется\n",
    "scaler = RobustScaler()\n",
    "for i in range(len(well_org_fill_md)):\n",
    "    well_org_fill_md[i][['CALI', 'RSHA', 'RMED', 'RDEP', 'RHOB', 'GR','NPHI', 'PEF', 'DTC', 'SP', 'BS']] = scaler.fit_transform(well_org_fill_md[i][['CALI', 'RSHA', 'RMED', 'RDEP', 'RHOB', 'GR','NPHI', 'PEF', 'DTC', 'SP', 'BS']])\n",
    "\n",
    "for i in range(len(well_all_fill_md)):\n",
    "    well_all_fill_md[i][['X_LOC', 'Y_LOC', 'Z_LOC','CALI', 'RSHA', 'RMED', 'RDEP', 'RHOB', 'GR', 'SGR', 'NPHI', 'PEF',\n",
    "       'DTC', 'SP', 'BS', 'ROP', 'DTS', 'DCAL', 'DRHO', 'MUDWEIGHT', 'RMIC',\n",
    "       'ROPA', 'RXO']] = scaler.fit_transform(well_all_fill_md[i][['X_LOC', 'Y_LOC', 'Z_LOC','CALI', 'RSHA', 'RMED', 'RDEP', 'RHOB', 'GR', 'SGR', 'NPHI', 'PEF',\n",
    "       'DTC', 'SP', 'BS', 'ROP', 'DTS', 'DCAL', 'DRHO', 'MUDWEIGHT', 'RMIC',\n",
    "       'ROPA', 'RXO']])\n",
    "\n",
    "for i in range(len(well_log_fill_md)):\n",
    "    well_log_fill_md[i][['CALI', 'RSHA', 'RMED', 'RDEP', 'RHOB', 'GR', 'SGR', 'NPHI',\n",
    "       'PEF', 'DTC', 'SP', 'BS', 'ROP', 'DTS', 'DCAL', 'DRHO', 'RMIC', 'ROPA',\n",
    "       'RXO']] = scaler.fit_transform(well_log_fill_md[i][['CALI', 'RSHA', 'RMED', 'RDEP', 'RHOB', 'GR', 'SGR', 'NPHI',\n",
    "       'PEF', 'DTC', 'SP', 'BS', 'ROP', 'DTS', 'DCAL', 'DRHO', 'RMIC', 'ROPA',\n",
    "       'RXO']])\n",
    "\n",
    "for i in range(len(well_slf_fill_md)):\n",
    "    well_slf_fill_md[i][['DRHO', 'DTC', 'SP', 'GR', 'RDEP']] = scaler.fit_transform(well_slf_fill_md[i][['DRHO', 'DTC', 'SP', 'GR', 'RDEP']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e5aef2",
   "metadata": {},
   "source": [
    "#### 2.3.2 Объединение индивидуальных скважинных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbed1ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_org_fill_md = pd.concat(well_org_fill_md)\n",
    "data_all_fill_md = pd.concat(well_all_fill_md)\n",
    "data_log_fill_md = pd.concat(well_log_fill_md)\n",
    "data_slf_fill_md = pd.concat(well_slf_fill_md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf448f3",
   "metadata": {},
   "source": [
    "#### 2.3.3 Разбиение  на фичи и таргет + работа с таргетом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a90be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_org_md = data_org_fill_md.drop(['WELL', 'FORCE_2020_LITHOFACIES_LITHOLOGY','FORCE_2020_LITHOFACIES_CONFIDENCE'], axis=1)\n",
    "X_all_md = data_all_fill_md.drop(['FORCE_2020_LITHOFACIES_LITHOLOGY','FORCE_2020_LITHOFACIES_CONFIDENCE'], axis=1)\n",
    "X_log_md = data_log_fill_md.drop(['WELL', 'FORCE_2020_LITHOFACIES_LITHOLOGY','FORCE_2020_LITHOFACIES_CONFIDENCE'], axis=1)\n",
    "X_slf_md = data_slf_fill_md.drop(['FORCE_2020_LITHOFACIES_LITHOLOGY','FORCE_2020_LITHOFACIES_CONFIDENCE'], axis=1)\n",
    "\n",
    "y_org_md = data_org_fill_md['FORCE_2020_LITHOFACIES_LITHOLOGY']\n",
    "y_all_md = data_all_fill_md['FORCE_2020_LITHOFACIES_LITHOLOGY']\n",
    "y_log_md = data_log_fill_md['FORCE_2020_LITHOFACIES_LITHOLOGY']\n",
    "y_slf_md = data_slf_fill_md['FORCE_2020_LITHOFACIES_LITHOLOGY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0b7968",
   "metadata": {},
   "outputs": [],
   "source": [
    "lithology_numbers = {30000: 0,\n",
    "                 65030: 1,\n",
    "                 65000: 2,\n",
    "                 80000: 3,\n",
    "                 74000: 4,\n",
    "                 70000: 5,\n",
    "                 70032: 6,\n",
    "                 88000: 7,\n",
    "                 86000: 8,\n",
    "                 99000: 9,\n",
    "                 90000: 10,\n",
    "                 93000: 11}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2cdca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_org_md = y_org_md.map(lithology_numbers)\n",
    "y_all_md = y_all_md.map(lithology_numbers)\n",
    "y_log_md = y_log_md.map(lithology_numbers)\n",
    "y_slf_md = y_slf_md.map(lithology_numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50328da1",
   "metadata": {},
   "source": [
    "#### 2.3.4 Разбиение на тренировочный и тестовый сеты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd44b482",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_org_md, X_test_org_md, y_train_org_md, y_test_org_md = train_test_split(X_org_md, y_org_md, train_size=0.70, random_state=42, stratify=y_org_md)\n",
    "X_train_all_md, X_test_all_md, y_train_all_md, y_test_all_md = train_test_split(X_all_md, y_all_md, train_size=0.70, random_state=42, stratify=y_all_md)\n",
    "X_train_log_md, X_test_log_md, y_train_log_md, y_test_log_md = train_test_split(X_log_md, y_log_md, train_size=0.70, random_state=42, stratify=y_log_md)\n",
    "X_train_slf_md, X_test_slf_md, y_train_slf_md, y_test_slf_md = train_test_split(X_slf_md, y_slf_md, train_size=0.70, random_state=42, stratify=y_slf_md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0d9732",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d37c3b1",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d01734f",
   "metadata": {},
   "source": [
    "# 3. Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7be5d9",
   "metadata": {},
   "source": [
    "### 3.1 Подбор гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d688578",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_flag == True:\n",
    "    def objective_xgb(trial):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_org_md, y_org_md, train_size=0.70, random_state=42, stratify=y_org_md)\n",
    "        dtrain = xgboost.DMatrix(X_train, label=y_train)\n",
    "        dvalid = xgboost.DMatrix(X_test, label=y_test)\n",
    "\n",
    "        param = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 500, 50),\n",
    "            \"num_class\": 12,\n",
    "            \"verbosity\": 0,\n",
    "            \"objective\": \"multi:softmax\",\n",
    "            \"tree_method\": \"gpu_hist\",\n",
    "            \"booster\": trial.suggest_categorical(\"booster\", [\"gbtree\", \"gblinear\", \"dart\"]),\n",
    "            \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-3, 1.0, log=False),\n",
    "            \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-3, 1.0, log=False),\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.2, 1.0),\n",
    "            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.2, 1.0),\n",
    "        }\n",
    "\n",
    "        if param[\"booster\"] in [\"gbtree\", \"dart\"]:\n",
    "            param[\"max_depth\"] = trial.suggest_int(\"max_depth\", 6, 16, step=1)\n",
    "            param[\"min_child_weight\"] = trial.suggest_int(\"min_child_weight\", 2, 8, step=1)\n",
    "            param[\"learning_rate\"] = trial.suggest_float(\"learning_rate\", 1e-3, 1.0, log=False)\n",
    "            param[\"gamma\"] = trial.suggest_float(\"gamma\", 1e-8, 1e-5, log=False)\n",
    "            param[\"grow_policy\"] = trial.suggest_categorical(\"grow_policy\", [\"depthwise\", \"lossguide\"])\n",
    "\n",
    "        if param[\"booster\"] == \"dart\":\n",
    "            param[\"sample_type\"] = trial.suggest_categorical(\"sample_type\", [\"uniform\", \"weighted\"])\n",
    "            param[\"normalize_type\"] = trial.suggest_categorical(\"normalize_type\", [\"tree\", \"forest\"])\n",
    "            param[\"rate_drop\"] = trial.suggest_float(\"rate_drop\", 1e-8, 1e-5, log=False)\n",
    "            param[\"skip_drop\"] = trial.suggest_float(\"skip_drop\", 1e-8, 1e-5, log=False)\n",
    "\n",
    "        num_round = 100\n",
    "        bst = xgboost.train(param, dtrain, num_round)\n",
    "        preds = bst.predict(dvalid)\n",
    "        accuracy = sklearn.metrics.accuracy_score(y_test, preds)\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e3b02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_flag == True:\n",
    "    def objective_cb(trial):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_org_md, y_org_md, train_size=0.70, random_state=42, stratify=y_org_md)\n",
    "\n",
    "        param = {\n",
    "            \"iterations\": 30,\n",
    "            \"loss_function\": \"MultiClass\",\n",
    "            \"task_type\": \"GPU\",\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.8),\n",
    "            \"depth\": trial.suggest_int(\"depth\", 10, 16),\n",
    "            \"bootstrap_type\": trial.suggest_categorical(\"bootstrap_type\", [\"Bayesian\", \"Bernoulli\"]),\n",
    "            \"grow_policy\": trial.suggest_categorical(\"grow_policy\", [\"SymmetricTree\", \"Depthwise\"])\n",
    "        }\n",
    "\n",
    "        cst = CatBoostClassifier(**param)\n",
    "        cst.fit(X_train, y_train, verbose=False, plot=False)\n",
    "        preds = cst.predict(X_test)\n",
    "        accuracy = sklearn.metrics.accuracy_score(y_test, preds)\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fe8413",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_flag == True:\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective_xgb, n_trials=1000, timeout=1600)\n",
    "\n",
    "    print(\"Number of finished trials: \", len(study.trials))\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: {}\".format(trial.value))\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885dcf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_flag == True:\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective_cb, n_trials=1000, timeout=1600)\n",
    "\n",
    "    print(\"Number of finished trials: \", len(study.trials))\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: {}\".format(trial.value))\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabcfa83",
   "metadata": {},
   "source": [
    "### 3.2 Настройка моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4809c242",
   "metadata": {},
   "outputs": [],
   "source": [
    "A=np.array([[0.    , 2.    , 3.5   , 3.    , 3.75  , 3.5   , 3.5   , 4.    , 4.    , 2.5   , 3.875 , 3.25  ],\n",
    "            [2.    , 0.    , 2.375 , 2.75  , 4.    , 3.75  , 3.75  , 3.875 , 4.    , 3.    , 3.75  , 3.    ],\n",
    "            [3.5   , 2.375 , 0.    , 2.    , 3.5   , 3.5   , 3.75  , 4.    , 4.    , 2.75  , 3.25  , 3.    ],\n",
    "            [3.    , 2.75  , 2.    , 0.    , 2.5   , 2.    , 2.25  , 4.    , 4.    , 3.375 , 3.75  , 3.25  ],\n",
    "            [3.75  , 4.    , 3.5   , 2.5   , 0.    , 2.625 , 2.875 , 3.75  , 3.25  , 3.    , 4.    , 3.625 ],\n",
    "            [3.5   , 3.75  , 3.5   , 2.    , 2.625 , 0.    , 1.375 , 4.    , 3.75  , 3.5   , 4.    , 3.625 ],\n",
    "            [3.5   , 3.75  , 3.75  , 2.25  , 2.875 , 1.375 , 0.    , 4.    , 3.75  , 3.125 , 4.    , 3.75  ],\n",
    "            [4.    , 3.875 , 4.    , 4.    , 3.75  , 4.    , 4.    , 0.    , 2.75  , 3.75  , 3.75  , 4.    ],\n",
    "            [4.    , 4.    , 4.    , 4.    , 3.25  , 3.75  , 3.75  , 2.75  , 0.    , 4.    , 4.    , 3.875 ],\n",
    "            [2.5   , 3.    , 2.75  , 3.375 , 3.    , 3.5   , 3.125 , 3.75  , 4.    , 0.    , 2.5   , 3.25  ],\n",
    "            [3.875 , 3.75  , 3.25  , 3.75  , 4.    , 4.    , 4.    , 3.75  , 4.    , 2.5   , 0.    , 4.    ],\n",
    "            [3.25  , 3.    , 3.    , 3.25  , 3.625 , 3.625 , 3.75  , 4.    , 3.875 , 3.25  , 4.    , 0.    ]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404bb5b9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Проверка гипотезы о происхождение матрицы весов\n",
    "if train_flag == True:\n",
    "    lm = data_log.drop(['FORCE_2020_LITHOFACIES_CONFIDENCE','WELL'], axis=1).groupby('FORCE_2020_LITHOFACIES_LITHOLOGY').mean().loc[:, :]\n",
    "    #lm = data_org.drop(['WELL', 'FORCE_2020_LITHOFACIES_CONFIDENCE'], axis=1).groupby('FORCE_2020_LITHOFACIES_LITHOLOGY').mean().loc[:, :]\n",
    "    #lm = data_all.drop(['WELL','FORMATION', 'GROUP', 'FORCE_2020_LITHOFACIES_CONFIDENCE'], axis=1).groupby('FORCE_2020_LITHOFACIES_LITHOLOGY').mean().loc[:, :]\n",
    "    fd = np.zeros((12, 12), dtype=\"float64\")\n",
    "    for i, l1 in enumerate([30000,65030,65000,80000,74000,70000,70032,88000,86000,99000,90000,93000]):\n",
    "        for j, l2 in enumerate([30000,65030,65000,80000,74000,70000,70032,88000,86000,99000,90000,93000]):\n",
    "            fd[i, j] = np.sqrt(sum(pow(a-b, 2) for a, b in zip(lm.loc[l1, :].values, lm.loc[l2, :].values)))\n",
    "\n",
    "    np.set_printoptions(linewidth=120)\n",
    "    print(np.round_(fd/16.94412535, decimals=3)) #расчёт расстояния по данным ГИС\n",
    "    #print(np.round_(fd/111.98208369, decimals=3)) #расчёт расстояния по данным организаторов\n",
    "    #print(np.round_(fd/31168.29385083, decimals=3)) #расчёт расстояния по всем данным"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23050777",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Рассчёт весов классов на основе матрицы в метрике оценки точности\n",
    "if train_flag == True:\n",
    "    classes = np.unique(y_train_org_md)\n",
    "    A_weights = np.ones(len(classes))\n",
    "    y_train_weights = np.ones(len(y_train_org_md))\n",
    "    for i in classes:\n",
    "        A_weights[i] = A[i].mean()\n",
    "    class_weights = dict(zip(classes, A_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394f66a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_flag == True:\n",
    "    #Org\n",
    "    y_train_org_md_weights = np.zeros(max(y_train_org_md.index)+1)\n",
    "    for i in y_train_org_md.index:\n",
    "        y_train_org_md_weights[i] = A_weights[y_train_org_md[i]]\n",
    "    y_train_org_md_weights = y_train_org_md_weights[y_train_org_md_weights!=0.0]\n",
    "\n",
    "    #All\n",
    "    y_train_all_md_weights = np.zeros(max(y_train_all_md.index)+1)\n",
    "    for i in y_train_all_md.index:\n",
    "        y_train_all_md_weights[i] = A_weights[y_train_all_md[i]]\n",
    "    y_train_all_md_weights = y_train_all_md_weights[y_train_all_md_weights!=0.0]\n",
    "\n",
    "    #Log\n",
    "    y_train_log_md_weights = np.zeros(max(y_train_log_md.index)+1)\n",
    "    for i in y_train_log_md.index:\n",
    "        y_train_log_md_weights[i] = A_weights[y_train_log_md[i]]\n",
    "\n",
    "    #Slf\n",
    "    y_train_slf_md_weights = np.zeros(max(y_train_slf_md.index)+1)\n",
    "    for i in y_train_slf_md.index:\n",
    "        y_train_slf_md_weights[i] = A_weights[y_train_slf_md[i]]\n",
    "    y_train_slf_md_weights = y_train_slf_md_weights[y_train_slf_md_weights!=0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecb4336",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_flag == True:\n",
    "    model_rf = RandomForestClassifier(n_estimators=50, random_state=42, class_weight='balanced', n_jobs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f67b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_flag == True:\n",
    "    param = {\n",
    "        'loss_function': 'MultiClass',\n",
    "        'eval_metric': 'MultiClass',\n",
    "        'early_stopping_rounds': 20,\n",
    "        'task_type': 'GPU',\n",
    "        'nan_mode': \"Forbidden\",\n",
    "        'random_seed': 42,\n",
    "        'class_weights': class_weights,\n",
    "        'iterations': 2500,\n",
    "        'learning_rate': 0.23714547752509413,\n",
    "        'depth': 15, #11\n",
    "        'bootstrap_type': 'Bernoulli',\n",
    "        'grow_policy': 'Depthwise'\n",
    "    }\n",
    "    \n",
    "    model_cb = CatBoostClassifier(**param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7abfc50",
   "metadata": {},
   "source": [
    "### 3.3 Обучение моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c8e766",
   "metadata": {},
   "source": [
    "#### 3.3.1 CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce3f65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_flag == True:\n",
    "    cst = model_cb.fit(X_train_org_md, y_train_org_md, verbose=False, plot=True)\n",
    "    cst.save_model('cst_model_org_md.dat')\n",
    "    y_pred_model_cb_org_md = cst.predict(X_test_org_md)\n",
    "\n",
    "    cat_features = ['WELL', 'GROUP', 'FORMATION']\n",
    "    cst = model_cb.fit(X_train_all_md, y_train_all_md, verbose=False, plot=True, cat_features=cat_features)\n",
    "    cst.save_model('cst_model_all_md.dat')\n",
    "    y_pred_model_cb_all_md = cst.predict(X_test_all_md)\n",
    "    cst.get_feature_importance()\n",
    "\n",
    "    cst = model_cb.fit(X_train_log_md, y_train_log_md, verbose=False, plot=True)\n",
    "    cst.save_model('cst_model_log_md.dat')\n",
    "    y_pred_model_cb_log_md = cst.predict(X_test_log_md)\n",
    "\n",
    "    cat_features = ['WELL', 'FORMATION']\n",
    "    cst = model_cb.fit(X_train_slf_md, y_train_slf_md, verbose=False, plot=True, cat_features=cat_features)\n",
    "    cst.save_model('cst_model_slf_md.dat')\n",
    "    y_pred_model_cb_slf_md = cst.predict(X_test_slf_md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cc2e0f",
   "metadata": {},
   "source": [
    "#### 3.3.2 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbfaf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_flag == True:\n",
    "    #Проблема с освобождением видеопамяти уже решена\n",
    "    param = {\n",
    "        'tree_method': 'gpu_hist',\n",
    "        'num_class': 12,\n",
    "        'verbosity': 0,\n",
    "        'objective': 'multi:softmax',\n",
    "        'eval_metric': 'mlogloss',\n",
    "        'n_estimators': 300,\n",
    "        'booster': 'gbtree',\n",
    "        'reg_lambda': 0.7782570197655274,\n",
    "        'reg_alpha': 0.6708911140908719,\n",
    "        'subsample': 0.4074545609407748,\n",
    "        'colsample_bytree': 0.9676511295252206,\n",
    "        'max_depth': 10,\n",
    "        'min_child_weight': 4,\n",
    "        'learning_rate': 0.2781337326653397,\n",
    "        'gamma': 4.6464337473120594e-06,\n",
    "        'grow_policy': 'lossguide'}\n",
    "    num_round = 3000\n",
    "    \n",
    "    #Org\n",
    "    dtrain = xgboost.DMatrix(X_train_org_md, label=y_train_org_md)\n",
    "    dtest = xgboost.DMatrix(X_test_org_md, label=y_test_org_md)\n",
    "    bst = xgboost.train(param, dtrain, num_round, evals=[(dtrain, 'train') , (dtest, 'test')], early_stopping_rounds=10)\n",
    "    joblib.dump(bst, 'xgb_model_org_md.dat')\n",
    "    bst.__del__() # удаление модели с её взаимосвязями для очистки графической памяти\n",
    "    bst = joblib.load('xgb_model_org_md.dat')\n",
    "    y_pred_model_xgb_org_md = bst.predict(dtest)\n",
    "    bst.__del__() # удаление модели с её взаимосвязями для очистки графической памяти\n",
    "    gc.collect()\n",
    "    print(y_pred_model_xgb_org_md)\n",
    "\n",
    "    #All\n",
    "    X_train_all_md[['WELL', 'GROUP', 'FORMATION']] = X_train_all_md[['WELL', 'GROUP', 'FORMATION']].astype('category')\n",
    "    X_test_all_md[['WELL', 'GROUP', 'FORMATION']] = X_test_all_md[['WELL', 'GROUP', 'FORMATION']].astype('category')\n",
    "    dtrain = xgboost.DMatrix(X_train_all_md, label=y_train_all_md, enable_categorical=True)\n",
    "    dtest = xgboost.DMatrix(X_test_all_md, label=y_test_all_md, enable_categorical=True)\n",
    "    bst = xgboost.train(param, dtrain, num_round, evals=[(dtrain, 'train') , (dtest, 'test')], early_stopping_rounds=10)\n",
    "    joblib.dump(bst, 'xgb_model_all_md.dat')\n",
    "    bst.__del__()\n",
    "    bst = joblib.load('xgb_model_all_md.dat')\n",
    "    y_pred_model_xgb_all_md = bst.predict(dtest)\n",
    "    bst.__del__()\n",
    "    gc.collect()\n",
    "    print(y_pred_model_xgb_all_md)\n",
    "\n",
    "    #Log\n",
    "    dtrain = xgboost.DMatrix(X_train_log_md, label=y_train_log_md)\n",
    "    dtest = xgboost.DMatrix(X_test_log_md, label=y_test_log_md)\n",
    "    bst = xgboost.train(param, dtrain, num_round, evals=[(dtrain, 'train') , (dtest, 'test')], early_stopping_rounds=10)\n",
    "    joblib.dump(bst, 'xgb_model_log_md.dat')\n",
    "    bst.__del__()\n",
    "    bst = joblib.load('xgb_model_log_md.dat')\n",
    "    y_pred_model_xgb_log_md = bst.predict(dtest)\n",
    "    bst.__del__()\n",
    "    gc.collect()\n",
    "    print(y_pred_model_xgb_log_md)\n",
    "\n",
    "    #Slf\n",
    "    X_train_slf_md[['WELL','FORMATION']] = X_train_slf_md[['WELL','FORMATION']].astype('category')\n",
    "    X_test_slf_md[['WELL','FORMATION']] = X_test_slf_md[['WELL','FORMATION']].astype('category')\n",
    "    dtrain = xgboost.DMatrix(X_train_slf_md, label=y_train_slf_md, enable_categorical=True)\n",
    "    dtest = xgboost.DMatrix(X_test_slf_md, label=y_test_slf_md, enable_categorical=True)\n",
    "    bst = xgboost.train(param, dtrain, num_round, evals=[(dtrain, 'train') , (dtest, 'test')], early_stopping_rounds=10)\n",
    "    joblib.dump(bst, 'xgb_model_slf_md.dat')\n",
    "    bst.__del__()\n",
    "    bst = joblib.load('xgb_model_slf_md.dat')\n",
    "    y_pred_model_xgb_slf_md = bst.predict(dtest)\n",
    "    bst.__del__()\n",
    "    gc.collect()\n",
    "    print(y_pred_model_xgb_slf_md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b23170",
   "metadata": {},
   "source": [
    "#### 3.3.3 Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0735c9b",
   "metadata": {},
   "source": [
    "##### 3.3.3.1 OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7eab019",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "encoded = pd.DataFrame(enc.fit_transform(X_train_slf_md[['WELL', 'FORMATION']]).toarray())\n",
    "X_train_slf_md_enc = X_train_slf_md.drop(['WELL', 'FORMATION'], axis=1)\n",
    "X_train_slf_md_enc.reset_index(drop=True, inplace=True)\n",
    "X_train_slf_md_enc = pd.merge(encoded, X_train_slf_md_enc, left_index=True, right_index=True)\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "encoded = pd.DataFrame(enc.fit_transform(X_test_slf_md[['WELL', 'FORMATION']]).toarray())\n",
    "X_test_slf_md_enc = X_test_slf_md.drop(['WELL', 'FORMATION'], axis=1)\n",
    "X_test_slf_md_enc.reset_index(drop=True, inplace=True)\n",
    "X_test_slf_md_enc = pd.merge(encoded, X_test_slf_md_enc, left_index=True, right_index=True)\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "encoded = pd.DataFrame(enc.fit_transform(X_train_all_md[['WELL', 'FORMATION', 'GROUP']]).toarray())\n",
    "X_train_all_md_enc = X_train_all_md.drop(['WELL', 'FORMATION', 'GROUP'], axis=1)\n",
    "X_train_all_md_enc.reset_index(drop=True, inplace=True)\n",
    "X_train_all_md_enc = pd.merge(encoded, X_train_all_md_enc, left_index=True, right_index=True)\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "encoded = pd.DataFrame(enc.fit_transform(X_test_all_md[['WELL', 'FORMATION', 'GROUP']]).toarray())\n",
    "X_test_all_md_enc = X_test_all_md.drop(['WELL', 'FORMATION', 'GROUP'], axis=1)\n",
    "X_test_all_md_enc.reset_index(drop=True, inplace=True)\n",
    "X_test_all_md_enc = pd.merge(encoded, X_test_all_md_enc, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43413f04",
   "metadata": {},
   "source": [
    "#####  3.3.3.2 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea3d85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = model_rf.fit(X_train_org_md, y_train_org_md)\n",
    "y_pred_model_rf_org_md = rf.predict(X_test_org_md)\n",
    "joblib.dump(rf, 'rf_model_org_md.dat')\n",
    "\n",
    "rf = model_rf.fit(X_train_all_md_enc, y_train_all_md)\n",
    "y_pred_model_rf_all_md = rf.predict(X_test_all_md_enc)\n",
    "joblib.dump(rf, 'rf_model_all_md.dat')\n",
    "\n",
    "rf = model_rf.fit(X_train_log_md, y_train_log_md)\n",
    "y_pred_model_rf_log_md = rf.predict(X_test_log_md)\n",
    "joblib.dump(rf, 'rf_model_log_md.dat')\n",
    "\n",
    "rf = model_rf.fit(X_train_slf_md_enc, y_train_slf_md)\n",
    "y_pred_model_rf_slf_md = rf.predict(X_test_slf_md_enc)\n",
    "joblib.dump(rf, 'rf_model_slf_md.dat')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37a07e7",
   "metadata": {},
   "source": [
    "### 3.4 Использование обученных моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505a735c",
   "metadata": {},
   "source": [
    "#### 3.4.1 CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8aca4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cst = CatBoostClassifier()\n",
    "cst.load_model('cst_model_org_md.dat')\n",
    "y_pred_model_cb_org_md = cst.predict(X_test_org_md)\n",
    "\n",
    "cst = CatBoostClassifier()\n",
    "cst.load_model('cst_model_all_md.dat')\n",
    "y_pred_model_cb_all_md = cst.predict(X_test_all_md)\n",
    "\n",
    "cst = CatBoostClassifier()\n",
    "cst.load_model('cst_model_log_md.dat')\n",
    "y_pred_model_cb_log_md = cst.predict(X_test_log_md)\n",
    "\n",
    "cst = CatBoostClassifier()\n",
    "cst.load_model('cst_model_slf_md.dat')\n",
    "y_pred_model_cb_slf_md = cst.predict(X_test_slf_md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c3d8ea",
   "metadata": {},
   "source": [
    "#### 3.4.2 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86338c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgboost.DMatrix(X_train_org_md, label=y_train_org_md)\n",
    "dtest = xgboost.DMatrix(X_test_org_md, label=y_test_org_md)\n",
    "bst = joblib.load('xgb_model_org_md.dat')\n",
    "y_pred_model_xgb_org_md = bst.predict(dtest)\n",
    "\n",
    "X_train_all_md[['WELL', 'GROUP', 'FORMATION']] = X_train_all_md[['WELL', 'GROUP', 'FORMATION']].astype('category')\n",
    "X_test_all_md[['WELL', 'GROUP', 'FORMATION']] = X_test_all_md[['WELL', 'GROUP', 'FORMATION']].astype('category')\n",
    "dtrain = xgboost.DMatrix(X_train_all_md, label=y_train_all_md, enable_categorical=True)\n",
    "dtest = xgboost.DMatrix(X_test_all_md, label=y_test_all_md, enable_categorical=True)\n",
    "bst = joblib.load('xgb_model_all_md.dat')\n",
    "y_pred_model_xgb_all_md = bst.predict(dtest)\n",
    "\n",
    "dtrain = xgboost.DMatrix(X_train_log_md, label=y_train_log_md)\n",
    "dtest = xgboost.DMatrix(X_test_log_md, label=y_test_log_md)\n",
    "bst = joblib.load('xgb_model_log_md.dat')\n",
    "y_pred_model_xgb_log_md = bst.predict(dtest)\n",
    "\n",
    "X_train_slf_md[['WELL','FORMATION']] = X_train_slf_md[['WELL','FORMATION']].astype('category')\n",
    "X_test_slf_md[['WELL','FORMATION']] = X_test_slf_md[['WELL','FORMATION']].astype('category')\n",
    "dtrain = xgboost.DMatrix(X_train_slf_md, label=y_train_slf_md, enable_categorical=True)\n",
    "dtest = xgboost.DMatrix(X_test_slf_md, label=y_test_slf_md, enable_categorical=True)\n",
    "bst = joblib.load('xgb_model_slf_md.dat')\n",
    "y_pred_model_xgb_slf_md = bst.predict(dtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd9937e",
   "metadata": {},
   "source": [
    "#### 3.4.3 Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6e9939",
   "metadata": {},
   "source": [
    "##### 3.4.3.1 OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2800bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "encoded = pd.DataFrame(enc.fit_transform(X_train_slf_md[['WELL', 'FORMATION']]).toarray())\n",
    "X_train_slf_md_enc = X_train_slf_md.drop(['WELL', 'FORMATION'], axis=1)\n",
    "X_train_slf_md_enc.reset_index(drop=True, inplace=True)\n",
    "X_train_slf_md_enc = pd.merge(encoded, X_train_slf_md_enc, left_index=True, right_index=True)\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "encoded = pd.DataFrame(enc.fit_transform(X_test_slf_md[['WELL', 'FORMATION']]).toarray())\n",
    "X_test_slf_md_enc = X_test_slf_md.drop(['WELL', 'FORMATION'], axis=1)\n",
    "X_test_slf_md_enc.reset_index(drop=True, inplace=True)\n",
    "X_test_slf_md_enc = pd.merge(encoded, X_test_slf_md_enc, left_index=True, right_index=True)\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "encoded = pd.DataFrame(enc.fit_transform(X_train_all_md[['WELL', 'FORMATION', 'GROUP']]).toarray())\n",
    "X_train_all_md_enc = X_train_all_md.drop(['WELL', 'FORMATION', 'GROUP'], axis=1)\n",
    "X_train_all_md_enc.reset_index(drop=True, inplace=True)\n",
    "X_train_all_md_enc = pd.merge(encoded, X_train_all_md_enc, left_index=True, right_index=True)\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "encoded = pd.DataFrame(enc.fit_transform(X_test_all_md[['WELL', 'FORMATION', 'GROUP']]).toarray())\n",
    "X_test_all_md_enc = X_test_all_md.drop(['WELL', 'FORMATION', 'GROUP'], axis=1)\n",
    "X_test_all_md_enc.reset_index(drop=True, inplace=True)\n",
    "X_test_all_md_enc = pd.merge(encoded, X_test_all_md_enc, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57352b1a",
   "metadata": {},
   "source": [
    "##### 3.4.3.2 Use trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc860c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = joblib.load('rf_model_org_md.dat')\n",
    "y_pred_model_rf_org_md = rf.predict(X_test_org_md)\n",
    "\n",
    "rf = joblib.load('rf_model_all_md.dat')\n",
    "y_pred_model_rf_all_md = rf.predict(X_test_all_md_enc)\n",
    "\n",
    "rf = joblib.load('rf_model_log_md.dat')\n",
    "y_pred_model_rf_log_md = rf.predict(X_test_log_md)\n",
    "\n",
    "rf = joblib.load('rf_model_slf_md.dat')\n",
    "y_pred_model_rf_slf_md = rf.predict(X_test_slf_md_enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ed7579",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e40adc",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a568ba",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a87a69e",
   "metadata": {},
   "source": [
    "# 4. Результаты"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ec15ac",
   "metadata": {},
   "source": [
    "### 4.1 Определение кастомной метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d3430a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(y_true, y_pred):\n",
    "    S = 0.0\n",
    "    y_true = y_true.astype(int)\n",
    "    y_pred = y_pred.astype(int)\n",
    "    for i in range(0, y_true.shape[0]):\n",
    "        S -= A[y_true[i], y_pred[i]]\n",
    "    return S/y_true.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071ed365",
   "metadata": {},
   "source": [
    "### 4.2 Подсчёт точности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503925e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('org')\n",
    "print(f'Result (Random Forest): {score(y_test_org_zr.values, y_pred_model_rf_org_zr)}')\n",
    "print(f'Result (CatBoost) (logloss): {score(y_test_org_zr.values, y_pred_model_cb_org_zr)}')\n",
    "print(f'Result (XGBoost) (logloss): {score(y_test_org_zr.values, y_pred_model_xgb_org_zr)}')\n",
    "\n",
    "print('all')\n",
    "print(f'Result (Random Forest): {score(y_test_all_zr.values, y_pred_model_rf_all_zr)}')\n",
    "print(f'Result (CatBoost) (logloss): {score(y_test_all_zr.values, y_pred_model_cb_all_zr)}')\n",
    "print(f'Result (XGBoost)(logloss): {score(y_test_all_zr.values, y_pred_model_xgb_all_zr)}')\n",
    "\n",
    "print('log')\n",
    "print(f'Result (Random Forest): {score(y_test_log_zr.values, y_pred_model_rf_log_zr)}')\n",
    "print(f'Result (CatBoost) (logloss): {score(y_test_log_zr.values, y_pred_model_cb_log_zr)}')\n",
    "print(f'Result (XGBoost) (logloss): {score(y_test_log_zr.values, y_pred_model_xgb_log_zr)}')\n",
    "\n",
    "print('slf')\n",
    "print(f'Result (Random Forest): {score(y_test_slf_zr.values, y_pred_model_rf_slf_zr)}')\n",
    "print(f'Result (CatBoost) (logloss): {score(y_test_slf_zr.values, y_pred_model_cb_slf_zr)}')\n",
    "print(f'Result (XGBoost) (logloss): {score(y_test_slf_zr.values, y_pred_model_xgb_slf_zr)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee13c984",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('CatBoost')\n",
    "print(f'Accuracy org: {sklearn.metrics.accuracy_score(y_test_org_zr.values, y_pred_model_cb_org_zr)}')\n",
    "print(f'Accuracy all: {sklearn.metrics.accuracy_score(y_test_all_zr.values, y_pred_model_cb_all_zr)}')\n",
    "print(f'Accuracy log: {sklearn.metrics.accuracy_score(y_test_log_zr.values, y_pred_model_cb_log_zr)}')\n",
    "print(f'Accuracy slf: {sklearn.metrics.accuracy_score(y_test_slf_zr.values, y_pred_model_cb_slf_zr)}')\n",
    "print('XGBooost')\n",
    "print(f'Accuracy org: {sklearn.metrics.accuracy_score(y_test_org_zr.values, y_pred_model_xgb_org_zr)}')\n",
    "print(f'Accuracy all: {sklearn.metrics.accuracy_score(y_test_all_zr.values, y_pred_model_xgb_all_zr)}')\n",
    "print(f'Accuracy log: {sklearn.metrics.accuracy_score(y_test_log_zr.values, y_pred_model_xgb_log_zr)}')\n",
    "print(f'Accuracy slf: {sklearn.metrics.accuracy_score(y_test_slf_zr.values, y_pred_model_xgb_slf_zr)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb712f73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
